ğŸ“˜NCERT Hybrid Retrievalâ€‘Augmented Generation (RAG) System

IntelÂ® Unnati Industrial Training Program 2025
A curriculumâ€‘aligned, multimodal NCERT questionâ€‘answering system built using Hybrid Retrieval + RAG, supporting text, OCR, and voice queries, with gradeâ€‘specific filtering (Class 5â€“10) and strict answer grounding.








ğŸ“‹TL;DR (Short Overview)



| Item             | Description                                                      |
| ---------------- | ---------------------------------------------------------------- |
| What is it?      | A Streamlitâ€‘based Hybrid RAG system for NCERT textbooks          |
| Why?             | To provide accurate, gradeâ€‘specific, curriculumâ€‘grounded answers |
| Core Idea        | Dense + Sparse Hybrid Retrieval + Controlled Generation          |
| Input Modes      | Text, Image (OCR), Voice (Whisper)                               |
| Grades Supported | Class 5 to Class 10                                              |
| Vector Store     | ChromaDB                                                         |
| Lines of Code    | ~3,000+ (Python)                                                 |
| License          | Academic / Educational                                           |









ğŸ¯Problem Statement â†’ Implementation Mapping



| Requirement            | Implementation                       | Location                                           |
| ---------------------- | ------------------------------------ | -------------------------------------------------- |
| Curriculumâ€‘aligned QA  | NCERTâ€‘only context grounding         | `rag_core.py`                                      |
| Gradeâ€‘specific answers | Metadata filtering (Class 5â€“10)      | `app.py`, `rag_core.py`                            |
| Hybrid Retrieval       | Dense embeddings + TFâ€‘IDF            | `build_doc_embeddings.py`, `build_sparse_index.py` |
| RAG Answer Generation  | Controlled prompts, no hallucination | `rag_core.py`                                      |
| OCR support            | Tesseract + OpenCV                   | `app.py`                                           |
| Voice input            | Whisper speechâ€‘toâ€‘text               | `app.py`                                           |
| Reâ€‘ranking             | MMR (diversity + relevance)          | `app.py`                                           |
| Evaluation             | Metric + LLMâ€‘based evaluation        | `evaluate_answers.py`, `llm_evaluate.py`           |



â–¶ï¸End-to-End Workflow

<img width="2013" height="1179" alt="image" src="https://github.com/user-attachments/assets/2609d4ed-4660-4fe3-949a-6828cc470b13" />







ğŸ—ï¸ System Architecture

<img width="2179" height="991" alt="image" src="https://github.com/user-attachments/assets/4b3627f3-6aae-4770-91d5-fda7ca4a988a" />



ğŸš€ Key Features

1.ğŸ“š NCERTâ€‘only, curriculumâ€‘grounded answers

2.ğŸ¯ Gradeâ€‘specific filtering (Class 5â€“10)

3.ğŸ” Hybrid Retrieval (Dense + Sparse)

4.ğŸ§  MMRâ€‘based reâ€‘ranking

5.ğŸ–¼ï¸ OCR support for textbook images

6.ğŸ¤ Voice input using Whisper

7.ğŸŒ Multilingual question support

8.ğŸ“ Answer summarization

9.ğŸ“‚ Source citation

10.ğŸ“Š Automated + LLMâ€‘based evaluation





## ğŸ“ Project Structure

```text
Intel-AI-Unnati-NCERT-RAG/
â”‚
â”œâ”€â”€ app.py
â”‚   â””â”€â”€ Streamlit frontend
â”‚       - Text, OCR, and Voice-based query input
â”‚       - Hybrid dense + sparse retrieval
â”‚       - MMR re-ranking
â”‚       - Grade-specific filtering (Class 5â€“10)
â”‚       - Displays answers, summaries, sources, and feedback
â”‚
â”œâ”€â”€ rag_core.py
â”‚   â””â”€â”€ Core RAG backend
â”‚       - NCERT-only answer generation
â”‚       - Query expansion
â”‚       - Language detection
â”‚       - Controlled prompt design
â”‚       - Lightweight conversation memory (summaries only)
â”‚
â”œâ”€â”€ build_doc_embeddings.py
â”‚   â””â”€â”€ Offline preprocessing script
â”‚       - Generates dense embeddings for NCERT chunks
â”‚       - Stores embeddings for fast reuse
â”‚
â”œâ”€â”€ build_sparse_index.py
â”‚   â””â”€â”€ Offline preprocessing script
â”‚       - Builds TF-IDF sparse index
â”‚       - Enables keyword-based retrieval
â”‚
â”œâ”€â”€ doc_embeddings.pkl        (ignored in Git)
â”œâ”€â”€ sparse_index.pkl          (ignored in Git)
â”‚
â”œâ”€â”€ evaluate_answers.py
â”‚   â””â”€â”€ Automated evaluation script
â”‚       - Quantitative evaluation of generated answers
â”‚
â”œâ”€â”€ llm_evaluate.py
â”‚   â””â”€â”€ LLM-based qualitative evaluation
â”‚       - Assesses relevance, faithfulness, and completeness
â”‚
â”œâ”€â”€ MiniOne.ipynb
â”‚   â””â”€â”€ End-to-end experimentation notebook
â”‚       - Data ingestion and cleaning
â”‚       - OCR extraction
â”‚       - Chunking and embedding generation
â”‚       - ChromaDB storage
â”‚
â”œâ”€â”€ base.ipynb
â”‚   â””â”€â”€ Initial baseline experiments
â”‚
â”œâ”€â”€ BaseProject.ipynb
â”‚   â””â”€â”€ Consolidated end-to-end workflow notebook
â”‚
â”œâ”€â”€ query_expansion_and_ans_generation.ipynb
â”‚   â””â”€â”€ Experiments with query expansion and answer generation
â”‚
â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Project dependencies
â”‚
â”œâ”€â”€ README.md
â”‚   â””â”€â”€ Project documentation
â”‚
â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ Git ignore rules for large data and generated artifacts
â”‚
â”œâ”€â”€ chroma_ncert_db/           (ignored in Git)
â”‚   â””â”€â”€ Persistent Chroma vector database
â”‚
â”œâ”€â”€ NcertData/                 (ignored in Git)
â”‚   â”œâ”€â”€ Class5/
â”‚   â”œâ”€â”€ Class6/
â”‚   â”œâ”€â”€ Class7/
â”‚   â”œâ”€â”€ Class8/
â”‚   â”œâ”€â”€ Class9/
â”‚   â””â”€â”€ Class10/
â”‚
â”œâ”€â”€ voice_query.wav            (ignored in Git)
â”œâ”€â”€ voice_query.json           (ignored in Git)
â”‚
â”œâ”€â”€ __pycache__/               (ignored in Git)
â”œâ”€â”€ .venv/                     (ignored in Git)
â””â”€â”€ .python-version
```




ğŸš€ Quick Start (< 2 minutes)

Follow the steps below to set up and run the NCERT Hybrid RAG system locally.

1ï¸âƒ£ Clone the Repository


                    git clone https://github.com/<your-username>/<your-repo-name>.git
                    cd <your-repo-name>

2ï¸âƒ£ Initialize Python Environment (Python 3.13.5)
This project uses Python 3.13.5.

Initialize the project using uv:

                        uv init --python 3.13.5

Create a virtual environment:

                         uv venv

Activate the virtual environment:

Linux / macOS

             source .venv/bin/activate

Windows (PowerShell)

             .venv\Scripts\Activate.ps1
Windows (CMD)

              .venv\Scripts\activate



3ï¸âƒ£ Install Dependencies

            pip install -r requirements.txt

4ï¸âƒ£ Prepare NCERT Dataset (Required)

The NCERT dataset (~7â€“8 GB) is not included in the repository due to size limits.
Download the dataset from the provided Google Drive link
Extract it into the project root in the following structure:

             NcertData/
             â”œâ”€â”€ Class5/
             â”œâ”€â”€ Class6/
             â”œâ”€â”€ Class7/
             â”œâ”€â”€ Class8/
             â”œâ”€â”€ Class9/
             â””â”€â”€ Class10/


5ï¸âƒ£ Download Prebuilt ChromaDB (Recommended)

To save time, a prebuilt Chroma vector database is provided separately.
Download chroma_ncert_db/ from the Google Drive link
Place it directly in the project root:

               chroma_ncert_db/

âš ï¸ This folder is not tracked in Git due to size constraints.



6ï¸âƒ£ (Optional) Build Indexes Manually

If you do NOT use the prebuilt ChromaDB, generate indexes locally:

            python build_doc_embeddings.py
            python build_sparse_index.py

This step:
Creates dense embeddings
Builds sparse TFâ€‘IDF index
Stores reusable artifacts locally


7ï¸âƒ£ Install & Configure Ollama (LLM Backend)
This project uses Mistral via Ollama for answer generation.

Install Ollama
Download and install Ollama from:
ğŸ‘‰ https://ollama.com

Verify installation:

           ollama --version

Pull the Mistral Model:

           ollama pull mistral

Run Mistral Locally:

            ollama run mistral
            
âš ï¸ Keep Ollama running in the background while using the app.


8ï¸âƒ£ Run the Streamlit Application

              streamlit run app.py
 
 The application will open automatically in your browser.


 
 ğŸ¯ Supported Input Modes
Once the app is running, you can ask questions using:

1.âœï¸ Text Input

2.ğŸ“· OCR Input (Upload textbook images)

3.ğŸ¤ Voice Input (Microphone-based queries)



ğŸ“„ Output Provided
For each query, the system generates:

1.âœ… NCERTâ€‘grounded answer

2.ğŸ“ Short summary

3.ğŸ“‚ Source citations

4.ğŸ“ Gradeâ€‘specific response (Class 5â€“10)


ğŸ§ª Evaluation (Optional)

Run automated evaluation:

            python evaluate_answers.py

Run LLM-based qualitative evaluation:

            python llm_evaluate.py



â™»ï¸ Notes
1.Large datasets and vector databases are excluded from Git

2.All results are reproducible using provided scripts

3.Answers are generated strictly from NCERT context only

4.Ollama must be running locally for answer generation





## ğŸ“¦ Dataset & Prebuilt Artifacts (Google Drive)

Due to GitHub storage limitations, large files required to run this project are **not included** in the repository.

The following resources are provided via Google Drive:

- ğŸ“š **NCERT Dataset (Class 5â€“10)** (~7â€“8 GB)
- ğŸ§  **Prebuilt Chroma Vector Database (`chroma_ncert_db`)**
- ğŸ“Š **Sparse Index (`sparse_index.pkl`)**
- ğŸ§¬ **Dense Embeddings (`doc_embeddings.pkl`)**
- ğŸ¤ Sample voice input files (for testing)

ğŸ‘‰ **Download from Google Drive:**  
ğŸ”— https://drive.google.com/drive/folders/1LsEtZPXwRtxqNKCctFVpgmYm7N-Uk1Y

---

### ğŸ“‚ After Download

Extract the contents into the **project root directory** so that the structure looks like this:

```text
NcertData/
â”œâ”€â”€ Class5/
â”œâ”€â”€ Class6/
â”œâ”€â”€ Class7/
â”œâ”€â”€ Class8/
â”œâ”€â”€ Class9/
â””â”€â”€ Class10/

chroma_ncert_db/
doc_embeddings.pkl
sparse_index.pkl




